{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d3769071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense,Dropout,GlobalAveragePooling2D,BatchNormalization \n",
    "from tensorflow.keras.applications import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca1e888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Paths\n",
    "TRAIN_DIR = \"../data/raw/NEU-DET/train\"\n",
    "VAL_DIR   = \"../data/raw/NEU-DET/validation\"\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54dd1ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1440 files belonging to 6 classes.\n",
      "Found 360 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b1a4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (preprocess_input(tf.cast(x, tf.float32)), y)\n",
    ")\n",
    "\n",
    "val_ds = val_ds.map(\n",
    "    lambda x, y: (preprocess_input(tf.cast(x, tf.float32)), y)\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67cbab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c8e7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(input_shape=IMG_SIZE + (3,), include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "94e8b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ac16e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.08),\n",
    "    tf.keras.layers.RandomZoom(0.15),\n",
    "    tf.keras.layers.RandomTranslation(0.08, 0.08),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62565e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
    "\n",
    "# Data augmentation (training only)\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Feature extraction\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Classification head\n",
    "inputs = tf.keras.Input(shape=(224,224,3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "outputs = tf.keras.layers.Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "18eb75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6b9a25ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"models/defect_detector_efficientnet.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "054886ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 453ms/step - accuracy: 0.9222 - loss: 0.2108 - val_accuracy: 0.8694 - val_loss: 0.4854\n",
      "Epoch 2/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 399ms/step - accuracy: 0.9937 - loss: 0.0251 - val_accuracy: 0.9083 - val_loss: 0.3360\n",
      "Epoch 3/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 395ms/step - accuracy: 0.9944 - loss: 0.0153 - val_accuracy: 0.9611 - val_loss: 0.1862\n",
      "Epoch 4/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 403ms/step - accuracy: 0.9937 - loss: 0.0123 - val_accuracy: 0.9694 - val_loss: 0.1297\n",
      "Epoch 5/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 406ms/step - accuracy: 0.9979 - loss: 0.0075 - val_accuracy: 0.9917 - val_loss: 0.0656\n",
      "Epoch 6/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 395ms/step - accuracy: 0.9972 - loss: 0.0078 - val_accuracy: 0.9889 - val_loss: 0.0456\n",
      "Epoch 7/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 403ms/step - accuracy: 0.9972 - loss: 0.0053 - val_accuracy: 0.9778 - val_loss: 0.0623\n",
      "Epoch 8/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 414ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.9889 - val_loss: 0.0400\n",
      "Epoch 9/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 412ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9861 - val_loss: 0.0400\n",
      "Epoch 10/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 407ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.9806 - val_loss: 0.0577\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2a0610e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "Fine_Tune_At = int(len(base_model.layers) * 0.8)\n",
    "\n",
    "for layer in base_model.layers[:Fine_Tune_At]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "23da6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa288280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 621ms/step - accuracy: 0.9660 - loss: 0.1379 - val_accuracy: 0.9944 - val_loss: 0.0124\n",
      "Epoch 2/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 517ms/step - accuracy: 0.9799 - loss: 0.1022 - val_accuracy: 0.9889 - val_loss: 0.0368\n",
      "Epoch 3/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 518ms/step - accuracy: 0.9924 - loss: 0.0284 - val_accuracy: 0.9694 - val_loss: 0.1905\n",
      "Epoch 4/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 517ms/step - accuracy: 0.9924 - loss: 0.0312 - val_accuracy: 0.9667 - val_loss: 0.2616\n",
      "Epoch 5/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 518ms/step - accuracy: 0.9875 - loss: 0.0794 - val_accuracy: 0.9806 - val_loss: 0.1256\n",
      "Epoch 6/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 516ms/step - accuracy: 0.9944 - loss: 0.0193 - val_accuracy: 0.9944 - val_loss: 0.0147\n"
     ]
    }
   ],
   "source": [
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "193ff04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/defect_detector_finetuned.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81659e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
